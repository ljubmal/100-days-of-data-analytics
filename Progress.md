# ðŸ“‹Progress tracker

---

ðŸ“… **Day 01:** January 13, 2023

**Today's topic**: Python for Data Science, week 1 and 2

**Todayâ€™s progress:** I get familiar with Python data structures and data types. Learned more about expressions, variables, strings, tuples, lists, sets, and dictionaries. Also prepared my VS Code for some serious work with python.

**Thoughts:** So far, so good.


---

ðŸ“… **Day 02:** January 14, 2023

**Today's topic**: Python for Data Science, week 3

**Todayâ€™s progress:** Learned about conditions, loops, functions and classes in Python. This class reminded me of my developer days, when creating classes and methods (functions) was part of my daily routine.


---
ðŸ“… **Day 03:** January 16, 2023

**Today's topic**: Python for Data Science, week 4 and 5

**Todayâ€™s progress:** Read about Pandas, NumPy, how to work with APIs and webscrapping. Also about performing ETL process (Extract, Transform, Load). Seems interesting so far. Next days I'm going to dedicate myself to polishing ETL techniques and working with APIs, since this seems to be very important step in data analytics process. Also, Pandas and NumPy have a lot of important functionalities that require more attention, and several days in a row to learn and improve skills on that.

---
ðŸ“… **Day 04, 05, 06:** January 17-19, 2023

**Today's topic**: ETL Process

**Todayâ€™s progress:** Investigating about ETL process and its steps. It's used to extract data from legacy systems, transform it, which means to clean and provide data consistency, and finally to load it to a target database. 
Extract can be performed from SQL or NoSQL servers, CRM or ERP systems, flatfiles, email and/or webpages.
Transforming include filtering, validating, authenticating, encrypting, formatting, depending on the business task.
Load implies that the transformed data is moved from the staging area into a target data warehouse.

---
ðŸ“… **Day 07:** February 28, 2023

**Today's topic**: Google Data Analytics materials

**Todayâ€™s progress:** From today, I'll repeat the material for Google Data Analytics Professional Certificate. I'll use my free time to commit myself to this track. Today I read about 6 steps of data analysis, data ecosystems, and the differences between data analysis and data science. I remind myself of 5 critical aspects of analytical thinking and what analytical skills mean. I read about spreadsheets, databases, and visualization tools. In the end, I read about fair practice in data analysis and the importance of an inclusive approach.

---
ðŸ“… **Day 08:** Mart 01, 2023

**Today's topic**: Google Data Analytics course 2, week 1 & 2 lessons.

**Todayâ€™s progress**: Today I read about data analyst job, problem solving using strategical thinking, what are steps that data analysts use to solve business problem. I've also read about 6 problem types, asking the SMART questions, and how to avoid leading, close-ended and vague questions. I read about reports and dashboards and find some very interesting solutions online. Also, learned about metrics, return of investments and customer rates. Later I remind myself of working with big data and its specifics.

---
ðŸ“… **Day 09 and 10:** Mart 05 and 06, 2023

**Today's topic**: Google Data Analytics course 2, week 3 & 4 lessons

**Today's progress:** Investigate a scope of work and its importance in the data analytic process. I remind myself of working with stakeholders and why it is important to have clear and open communication with them as well as other members of the team who participate in the data analysis process. Also, read about how dirty data may harm analysis and, as a result - the business, and what to do when there is not enough data or when we have to deal with dirty data. It's clear why data integrity is crucial - it directly affects the analysis result.

---
ðŸ“… **Day 11 and 12:** Mart 07 and 08, 2023

**Today's topic**: Google Data Analytics Course 3, week 1 & 2 lessons

**Today's progress:** I read about data types and structures, what factors to consider when collecting data, data modeling and its 3 levels (conceptual, logical, and physical), and techniques - UML and ER diagrams. I also read about wide and long data. One of the essential parts of preparing data for analysis is data transformation, a process where we adjust our data for further research. That includes adding, copying, replicating data, deleting missing records, standardizing names of variables, renaming or combining columns, and saving files in different formats (.xlsx to .csv, for example). 
I read about biases in data (sampling, observer, interpretation, and confirmation biases). I learned why data credibility is important and the ROCCC process for ensuring credibility. Ethics and data ethics and its 6 aspects (ownership, transaction transparency, consent, currency, privacy,  protection, and openness. Learned about data privacy and protection and what is considered a person's legal rights to their data. Also, read about 3 principles of data openness (openness, reuse and distribution, and interoperability) and Personal identifiable information (PII).

---
ðŸ“… **Day 13:** Mart 09, 2023

**Today's topic**: Google Data Analytics Course 3, week 3 lesson

**Today's progress:** I read about relational databases and installed Northwind, AdventureWorksLT, and Pubs databases for practice purposes. Then I use guidelines from the course - inspecting datasets, finding NULL values, exploring data types, fields, and values, and relationships between tables...
I read more about types of metadata (descriptive, structural, and administrative) and why they are important (putting data into context makes the data more reliable). Way of storing metadata - in a single central location. Data governance - manages roles and responsibilities related to data assets. Metadata specialists - create basic metadata information.
I learned more about internal and external data, naming conventions, data security, and its purpose.

---
ðŸ“… **Day 14 & 15:** Mart 10 & 11, 2023

**Today's topic**: Google Data Analytics Course 3, week 4 lesson

**Today's progress:** I practiced importing data from different data sources. External - from .csv and .xlsx files and exporting SQL tables as CSV files for further use. I practiced combining data from multiple sources, which reminded me that data cleaning and adjusting format is necessary before merging data into one table. In my case, there were different date formats (dd/mm/yyyy and mm/dd/yyyy with long time format), and a number of decimal places for 'float' data needed adjustment. I practiced importing data in SQL Server on my computer (restoring from .bak file and through executing scripts), accessing data from the BigQuery console and Kaggle, and uploading data to both.

**Thoughts:** BigQuery is a working environment much easier to use for now, since SQL can be directly written, while in Kaggle, some programming needs to be done (with Python or R) to set the notebook environment for use every time. However, Kaggle allows us to make notebooks or scripts, while BigQuery and SQL Server are used to query results and save queries as scripts. SQL Server also allows us to perform CRUD (Create, Read, Update, Delete) operations on data, while in BigQuery, we can only query data with the basic account.

---
ðŸ“… **Day 16:** Mart 13, 2023

**Today's topic**: Google Data Analytics Course 4, week 1

**Today's progress:** I learned about data integrity, why it is crucial, and how it can be compromised at any time data is replicated, transferred, or manipulated in any way. Data can also be compromised through human error, viruses, malware, hacking, or system failures.
I read about different problems with data and what to do when there is no data, too little data, or when data contain errors. Also, how to deal with insufficient data.
I learn about sample size terminology (population, sample, margin of error, confidence level, confidence interval, and statistical significance).
Further, I learn about statistical power and hypothesis testing and what it means for the result to be statistically significant, and what to do when there is no data.

**Thoughts:** It takes special caution when merging data from different sources since there is usually no common data formatting. Data constraints should be applied here and provide criteria for validity and safe analysis. Working with date formats is a special treat since it can be formatted in several ways, sometimes recognized as a text or varchar in sql. Important to remember is not to use a sample size of less than 30 and that the confidence level must be at least 90%, 95% even better.

---
ðŸ“… **Day 17:** Mart 14, 2023

**Today's topic**: Google Data Analytics Course 4, week 2

**Today's progress:** I read about types of human errors as the most common factor for poor-quality data. Also, read about other types of dirty data (duplicated, outdated, incomplete, incorrect/inaccurate, and inconsistent data) and why data validation is important. Further, I learned about principles of data integrity (validity, accuracy, completeness), data cleaning tools, techniques, and mistakes.

---
ðŸ“… **Day 18:** Mart 15, 2023

**Today's topic**: Google Data Analytics Course 4, week 3

**Today's progress:** 

